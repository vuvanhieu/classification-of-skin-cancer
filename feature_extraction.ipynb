{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "\n",
    "base_skin_dir = os.path.join('E:\\\\Research\\\\Skin-Cancer-Classification-Using-CNN-Deep-Learning-Algorithm-master\\\\archive\\\\', 'skin_img')\n",
    "\n",
    "imageid_path_dict = {}\n",
    "\n",
    "for images in os.listdir(base_skin_dir):\n",
    "    # check if the image ends with png or jpg or jpeg\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        temp = os.path.join(base_skin_dir, images)\n",
    "        # temp = os.path.splitext(os.path.basename(temp))[0]\n",
    "        imageid_path_dict[temp] = str(images)\n",
    "\n",
    "# imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "#                    for x in glob(os.path.join(base_skin_dir, '*.','jpg'))}\n",
    "# print(imageid_path_dict)\n",
    "\n",
    "lesion_dict = {     \n",
    "                  'nv': 'Melanocytic nevi',\n",
    "                  'mel': 'Melanoma',\n",
    "                  'bkl': 'Benign keratosis-like lesions ',\n",
    "                  'bcc': 'Basal cell carcinoma',\n",
    "                  'akiec': 'Actinic keratoses',\n",
    "                  'vasc': 'Vascular lesions',\n",
    "                  'df': 'Dermatofibroma'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0024306.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>E:\\Research\\Skin-Cancer-Classification-Using-C...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0024307.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>E:\\Research\\Skin-Cancer-Classification-Using-C...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0024308.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>E:\\Research\\Skin-Cancer-Classification-Using-C...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0024309.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>E:\\Research\\Skin-Cancer-Classification-Using-C...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0024310.jpg</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>E:\\Research\\Skin-Cancer-Classification-Using-C...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id          image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0024306.jpg  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0024307.jpg  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0024308.jpg  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0024309.jpg  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0024310.jpg  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  E:\\Research\\Skin-Cancer-Classification-Using-C...   \n",
       "1  E:\\Research\\Skin-Cancer-Classification-Using-C...   \n",
       "2  E:\\Research\\Skin-Cancer-Classification-Using-C...   \n",
       "3  E:\\Research\\Skin-Cancer-Classification-Using-C...   \n",
       "4  E:\\Research\\Skin-Cancer-Classification-Using-C...   \n",
       "\n",
       "                        cell_type  cell_codes  \n",
       "0  Benign keratosis-like lesions            2  \n",
       "1  Benign keratosis-like lesions            2  \n",
       "2  Benign keratosis-like lesions            2  \n",
       "3  Benign keratosis-like lesions            2  \n",
       "4  Benign keratosis-like lesions            2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('E:\\\\Research\\\\Skin-Cancer-Classification-Using-CNN-Deep-Learning-Algorithm-master\\\\archive\\\\HAM10000_metadata.csv')\n",
    "temp = imageid_path_dict.keys()\n",
    "path = []\n",
    "id = []\n",
    "for i in temp:\n",
    "    head_tail = os.path.split(i)\n",
    "    path.append(str(i))\n",
    "    id.append(str(head_tail[1]))\n",
    "dataset['path'] = path\n",
    "dataset['image_id'] = id \n",
    "dataset['cell_type'] = dataset['dx'].map(lesion_dict.get)\n",
    "dataset['cell_codes'] = pd.Categorical(dataset['cell_type']).codes\n",
    "dataset['age'].fillna((dataset['age'].mean()), inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=dataset,\n",
    "x_col='path',\n",
    "y_col='cell_type',\n",
    "batch_size=15, target_size=(224, 224), class_mode='categorical',subset = 'training')\n",
    "\n",
    "# validation_generator =  train_datagen.flow_from_dataframe(dataframe=dataset, \n",
    "# x_col='path',\n",
    "# y_col='cell_type',\n",
    "# batch_size=15, target_size=(224, 224), class_mode='categorical',subset = 'validation')\n",
    "\n",
    "# test_generator =  test_datagen.flow_from_dataframe(dataframe=test_df, \n",
    "# x_col='path',\n",
    "# y_col='cell_type',\n",
    "# batch_size=15, target_size=(224, 224), class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "n_classes=7\n",
    "n_steps = train_generator.samples // 15\n",
    "# n_val_steps = validation_generator.samples // 15\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 featture extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base_vgg16 = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "conv_base_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_generator.labels\n",
    "BATCH_SIZE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 1690s 3s/step\n"
     ]
    }
   ],
   "source": [
    "features_vgg16 = conv_base_vgg16.predict(train_generator, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10015, 7, 7, 512)\n",
      "(10015, 25088)\n"
     ]
    }
   ],
   "source": [
    "print(type(features_vgg16))\n",
    "features_vgg16.flatten()\n",
    "print(features_vgg16.shape)\n",
    "features_vgg16 = features_vgg16.reshape((features_vgg16.shape[0], 7 * 7 * 512))\n",
    "print(features_vgg16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit vào dữ liệu\n",
    "scaler.fit(features_vgg16)\n",
    "\n",
    "# Thực hiện transform scale\n",
    "scale_features_vgg16 = scaler.transform(features_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scale_features_vgg16)\n",
    "pca_features_vgg16 = pca.transform(scale_features_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('vgg16_data.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.create_dataset('features', data=pca_features_vgg16, dtype=\"uint16\", compression=\"gzip\")\n",
    "hf.create_dataset('label', data=label, compression=\"gzip\")\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  2]\n",
      " [ 0 47]\n",
      " ...\n",
      " [ 1 50]\n",
      " [ 0  0]\n",
      " [ 0  0]]\n",
      "[2 2 2 ... 0 0 5]\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('vgg16_data.h5', 'r')\n",
    "hf.keys()\n",
    "n1 = hf.get('features')\n",
    "print(np.array(n1))\n",
    "n2 = hf.get('label')\n",
    "print(np.array(n2))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_vgg19 = VGG19(include_top=False,\n",
    "                weights='imagenet', \n",
    "                input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 1835s 3s/step\n"
     ]
    }
   ],
   "source": [
    "features_vgg19 = conv_base_vgg19.predict(train_generator, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10015, 7, 7, 512)\n",
      "(10015, 25088)\n"
     ]
    }
   ],
   "source": [
    "print(type(features_vgg19))\n",
    "features_vgg19.flatten()\n",
    "print(features_vgg19.shape)\n",
    "features_vgg19 = features_vgg19.reshape((features_vgg19.shape[0], 7 * 7 * 512))\n",
    "print(features_vgg19.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit vào dữ liệu\n",
    "scaler.fit(features_vgg19)\n",
    "# Thực hiện transform scale\n",
    "scale_features_vgg19 = scaler.transform(features_vgg19)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scale_features_vgg19)\n",
    "pca_features_vgg19 = pca.transform(scale_features_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('vgg19_data.h5', 'w')\n",
    "hf.create_dataset('features', data=pca_features_vgg19, dtype=\"uint16\", compression=\"gzip\")\n",
    "hf.create_dataset('label', data=label, compression=\"gzip\")\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  0]\n",
      " [ 2 22]\n",
      " ...\n",
      " [ 0 18]\n",
      " [ 0  7]\n",
      " [ 0  0]]\n",
      "[2 2 2 ... 0 0 5]\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('vgg19_data.h5', 'r')\n",
    "hf.keys()\n",
    "n1 = hf.get('features')\n",
    "print(np.array(n1))\n",
    "n2 = hf.get('label')\n",
    "print(np.array(n2))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50 feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50 = tf.keras.applications.ResNet50(include_top=False,\n",
    "\n",
    "                   input_shape=(180,180,3),\n",
    "\n",
    "                   pooling='avg',classes=7,\n",
    "\n",
    "                   weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator_1 = train_datagen.flow_from_dataframe(dataframe=dataset,\n",
    "x_col='path',\n",
    "y_col='cell_type',\n",
    "batch_size=15, target_size=(180, 180), class_mode='categorical',subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 677s 1s/step\n"
     ]
    }
   ],
   "source": [
    "features_resnet50 = model_resnet50.predict(train_generator_1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10015, 2048)\n",
      "(10015, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(type(features_resnet50))\n",
    "features_resnet50.flatten()\n",
    "print(features_resnet50.shape)\n",
    "# features_resnet50 = features_resnet50.reshape((features_resnet50.shape[0], 7 * 7 * 512))\n",
    "print(features_resnet50.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit vào dữ liệu\n",
    "scaler.fit(features_resnet50)\n",
    "# Thực hiện transform scale\n",
    "scale_features_resnet50 = scaler.transform(features_resnet50)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scale_features_resnet50)\n",
    "pca_features_resnet50 = pca.transform(scale_features_resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('resnet50_data.h5', 'w')\n",
    "hf.create_dataset('features', data=pca_features_resnet50, dtype=\"uint16\", compression=\"gzip\")\n",
    "hf.create_dataset('label', data=label, compression=\"gzip\")\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0]\n",
      " [4 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 5]\n",
      " [0 0]]\n",
      "[2 2 2 ... 0 0 5]\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('resnet50_data.h5', 'r')\n",
    "hf.keys()\n",
    "n1 = hf.get('features')\n",
    "print(np.array(n1))\n",
    "n2 = hf.get('label')\n",
    "print(np.array(n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model():\n",
    "    # Defines &amp; compiles the model\n",
    "    classifier=keras.models.Sequential()\n",
    "    classifier.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
    "                            padding= 'valid', activation= 'relu',\n",
    "                            input_shape= (227,227,3),\n",
    "                            kernel_initializer= 'he_normal'))\n",
    "    classifier.add(MaxPool2D(pool_size=(3,3), strides= (2,2),\n",
    "                            padding= 'valid', data_format= None))\n",
    "\n",
    "    classifier.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "    classifier.add(MaxPool2D(pool_size=(3,3), strides= (2,2),\n",
    "                            padding= 'valid', data_format= None)) \n",
    "\n",
    "    classifier.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "    classifier.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "    classifier.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                    padding= 'same', activation= 'relu',\n",
    "                    kernel_initializer= 'he_normal'))\n",
    "\n",
    "    classifier.add(MaxPool2D(pool_size=(3,3), strides= (2,2),\n",
    "                            padding= 'valid', data_format= None))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator_2 = train_datagen.flow_from_dataframe(dataframe=dataset,\n",
    "x_col='path',\n",
    "y_col='cell_type',\n",
    "batch_size=15, target_size=(227, 227), class_mode='categorical',subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 151s 225ms/step\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = gen_model()\n",
    "features_alexnet = alexnet_model.predict(train_generator_2, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10015, 6, 6, 256)\n",
      "(10015, 9216)\n"
     ]
    }
   ],
   "source": [
    "print(type(features_alexnet))\n",
    "features_alexnet.flatten()\n",
    "print(features_alexnet.shape)\n",
    "features_alexnet = features_alexnet.reshape((features_alexnet.shape[0], 6 * 6 * 256))\n",
    "print(features_alexnet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit vào dữ liệu\n",
    "scaler.fit(features_alexnet)\n",
    "# Thực hiện transform scale\n",
    "scale_features_alexnet = scaler.transform(features_alexnet)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scale_features_alexnet)\n",
    "pca_features_alexnet = pca.transform(scale_features_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('alexnet_data.h5', 'w')\n",
    "hf.create_dataset('features', data=pca_features_alexnet, dtype=\"uint16\", compression=\"gzip\")\n",
    "hf.create_dataset('label', data=label, compression=\"gzip\")\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  5]\n",
      " [48  0]\n",
      " [ 0  0]\n",
      " ...\n",
      " [ 0 22]\n",
      " [20  0]\n",
      " [ 0  0]]\n",
      "[2 2 2 ... 0 0 5]\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('alexnet_data.h5', 'r')\n",
    "hf.keys()\n",
    "n1 = hf.get('features')\n",
    "print(np.array(n1))\n",
    "n2 = hf.get('label')\n",
    "print(np.array(n2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
